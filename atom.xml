<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Superbishop.github.io</id>
    <title>Bishop&apos;s Learning Space</title>
    <updated>2019-09-23T05:04:58.235Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Superbishop.github.io"/>
    <link rel="self" href="https://Superbishop.github.io/atom.xml"/>
    <subtitle>Live and learn. </subtitle>
    <logo>https://Superbishop.github.io/images/avatar.png</logo>
    <icon>https://Superbishop.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Bishop&apos;s Learning Space</rights>
    <entry>
        <title type="html"><![CDATA[正则表达式]]></title>
        <id>https://Superbishop.github.io/post/qlZcHAhor</id>
        <link href="https://Superbishop.github.io/post/qlZcHAhor">
        </link>
        <updated>2019-09-10T03:51:52.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p><strong>概念:针对字符串进行数据筛选的表达式(匹配), eg:  import re</strong></p>
</li>
<li>
<p><strong>原子:正则表达式中实现匹配的基本单位</strong></p>
</li>
<li>
<p>以普通字符作为原子</p>
</li>
<li>
<p>匹配通用字符<br>
\w 任意字母/数字/下划线<br>
\W 和小写w相反<br>
\d 十进制数字<br>
\D 除了十进制数以外的值<br>
\s 空白字符<br>
\S 非空白字符</p>
</li>
<li>
<p>匹配数字/英文/中文<br>
数字 [0,9]<br>
英文 [a,z][A,Z]<br>
中文[\u4e00-\u9fa5]</p>
</li>
<li>
<p>原子表:定义一组平等的原子, eg:  pat=&quot;1[3578]\d\d\d\d\d\d\d\d\d&quot;</p>
</li>
<li>
<p><strong>元字符:正则表达式中具有特殊意义的字符</strong><br>
.     匹配任意字符(\n 除外)<br>
^   匹配字符串开始位置 eg: ^136<br>
$    匹配字符串中结束的位置 eg:666$<br>
&quot;*&quot;    重复0/1/多次前面原子   eg: \d<br>
?      重复0/1次前面的原子   eg:\d?<br>
&quot;+&quot;  重复1/多次前面的原子 eg:\d+</p>
</li>
</ul>
<p>匹配固定次数<br>
{n} 前面的原子出现n次<br>
{n,} 前面的原子出现至少出现n次<br>
{n,m} 出现次数介于n-m之间</p>
<ul>
<li><strong>多个正则表达式可用或&quot;|&quot;符号连接,从而实现多种数据匹配</strong></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[处理get请求]]></title>
        <id>https://Superbishop.github.io/post/l99V4EeeY</id>
        <link href="https://Superbishop.github.io/post/l99V4EeeY">
        </link>
        <updated>2019-07-28T03:58:42.000Z</updated>
        <content type="html"><![CDATA[<pre><code>import urllib
from urllib import request
# https://www.baidu.com/s?wd=%E5%85%8D%E8%B4%B9%E4%BB%A3%E7%90%86IP # url 编码
url = &quot;http://www.baidu.com/s?&quot;
wd = {&quot;wd&quot;:&quot;免费代理IP&quot;}

# 构造url编码
wdd = urllib.parse.urlencode(wd)

url = url + wdd
req = request.Request(url)
response = request.urlopen(req)
print(response.read().decode())
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[反爬虫机制2:代理IP爬去网站]]></title>
        <id>https://Superbishop.github.io/post/o3jSS0M9C</id>
        <link href="https://Superbishop.github.io/post/o3jSS0M9C">
        </link>
        <updated>2019-07-28T02:55:46.000Z</updated>
        <content type="html"><![CDATA[<pre><code>proxylist = [
    {&quot;http&quot;:&quot;47.107.186.18:8118&quot;},
    {&quot;http&quot;:&quot;101.132.164.113:8118&quot;},
    {&quot;http&quot;:&quot;121.232.194.196:9000&quot;},
    {&quot;http&quot;:&quot;112.111.97.101:9000&quot;},
    {&quot;http&quot;:&quot;175.44.151.198:9000&quot;}
]

# 随机选取代理IP
proxy = random.choice(proxylist)
print(proxy)

# 构建代理处理器对象
proxyHandler = request.ProxyHandler(proxy)

# 创建自定义opener
opener = request.build_opener(proxyHandler)

# 创建自定义请求对象
request = request.Request(url)

response = opener.open(request)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[自定义opener 以及全局opener的创建方法]]></title>
        <id>https://Superbishop.github.io/post/TbXZS3u2p</id>
        <link href="https://Superbishop.github.io/post/TbXZS3u2p">
        </link>
        <updated>2019-07-17T06:07:36.000Z</updated>
        <content type="html"><![CDATA[<h4 id="通常我们默认使用的urlopen它是一个特殊的opener也就是模块自动构建好的但基本的urlopen不支持代理ipcookie等其他httphttps高级功能因此需要自动以opener">通常我们默认使用的urlopen,它是一个特殊的opener,也就是模块自动构建好的,但基本的urlopen()不支持代理IP/cookie等其他HTTP/HTTPS高级功能,因此需要自动以opener.</h4>
<h5 id="通过-reqeustbuildopener创建自定义opener对象使用自定义的opener对象调用open方法发送请求">* 通过 reqeust.build.opener()创建自定义opener对象,使用自定义的opener对象,调用open()方法发送请求</h5>
<h5 id="若程序全局都使用自定义opener通过requestinstallopener将自定义的opener对象定义为全局opener即若之后凡是调用urlopen都将使用该opener">* 若程序全局都使用自定义opener,通过request.install.opener()将自定义的opener对象定义为全局opener,即若之后凡是调用urlopen,都将使用该opener</h5>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[反爬虫机制一]]></title>
        <id>https://Superbishop.github.io/post/yzZXoI4C0</id>
        <link href="https://Superbishop.github.io/post/yzZXoI4C0">
        </link>
        <updated>2019-07-17T05:14:28.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<h4 id="反爬虫机制一判断用户是否是浏览器访问而非通过爬虫程序的urllib进行访问">反爬虫机制一:判断用户是否是浏览器访问,而非通过爬虫程序的urllib进行访问</h4>
</li>
<li>
<h4 id="应对方法伪装浏览器进行访问">应对方法:伪装浏览器进行访问</h4>
</li>
</ul>
<pre><code>header={
&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot;
} #构造请求头信息,包含进user-agent信息

req=request.Request(url,headers=header)#自定义请求对象将构造的请求头封装进去


</code></pre>
<h4 id="同时很多时候会添加多个user-agent进行随机爬虫防止被网页识别并拦截"><strong>同时,很多时候会添加多个user-agent进行随机爬虫,防止被网页识别并拦截</strong></h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[自定义请求]]></title>
        <id>https://Superbishop.github.io/post/zxPVKJyYZ</id>
        <link href="https://Superbishop.github.io/post/zxPVKJyYZ">
        </link>
        <updated>2019-07-17T04:44:58.000Z</updated>
        <content type="html"><![CDATA[<h4 id="正常情况下引入request模块request会自动创建请求对象">正常情况下,引入request模块,request会自动创建请求对象.</h4>
<pre><code>response=reqeust.urlopen(url).read().decode() #发送请求,获取响应并解码
</code></pre>
<h4 id="但往往爬虫时需要创建自定义请求对象使我们能封装更多信息进行请求">但往往爬虫时需要创建自定义请求对象,使我们能封装更多信息进行请求.</h4>
<pre><code>req=request.Request(url) #创建自定义请求对象
response=reqeust.urlopen(req).read().decode() #发送请求,获取响应并解码
</code></pre>
<p>#####前后两种request,不同点在于,第一种只针对url自动创建了请求对象,而第二种自定义的Request可以封装更多信息,不仅仅是url,还可以是cookies等其他信息,对抗反爬虫机制.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[爬虫与反爬虫对抗策略]]></title>
        <id>https://Superbishop.github.io/post/UxeS8jyWy</id>
        <link href="https://Superbishop.github.io/post/UxeS8jyWy">
        </link>
        <updated>2019-07-13T23:21:42.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-爬虫几个重要基本概念">一. 爬虫几个重要基本概念</h3>
<ul>
<li>
<h4 id="爬虫自动获取网站数据的程序">爬虫:自动获取网站数据的程序</h4>
</li>
<li>
<h4 id="反爬虫使用技术手段防止爬虫程序爬取数据">反爬虫：使用技术手段防止爬虫程序爬取数据</h4>
</li>
<li>
<h4 id="误伤反爬虫技术将普通用户识别为爬虫这种情况多出现在封ip中例如学校网络-小区网络再或者网络网络都是共享一个公共ip这个时候如果是封ip就会导致很多正常访问的用户也无法获取到数据-所以相对来说封ip的策略不是特别好通常都是禁止某ip一段时间访问">误伤：反爬虫技术将普通用户识别为爬虫，这种情况多出现在封ip中，例如学校网络、小区网络再或者网络网络都是共享一个公共ip，这个时候如果是封ip就会导致很多正常访问的用户也无法获取到数据。所以相对来说封ip的策略不是特别好，通常都是禁止某ip一段时间访问。</h4>
</li>
<li>
<h4 id="成本反爬虫也是需要人力和机器成本">成本：反爬虫也是需要人力和机器成本</h4>
</li>
<li>
<h4 id="拦截成功拦截爬虫一般拦截率越高误伤率也就越高">拦截：成功拦截爬虫，一般拦截率越高，误伤率也就越高</h4>
</li>
</ul>
<h3 id="二-爬虫与反爬虫对抗举例">二. 爬虫与反爬虫对抗举例:</h3>
<p><img src="https://Superbishop.github.io/post-images/1563060420392.png" alt=""></p>
<h3 id="三-python应对反爬虫机制策略总结">三. Python应对反爬虫机制策略总结:</h3>
<h4 id="1-反爬虫机制user-agent解析">1. 反爬虫机制:user-agent解析</h4>
<h4 id="应对机制fake-user-agent通过设定request-headers中的user-agent进行突破">应对机制:fake user-agent,通过设定Request Headers中的User-Agent进行突破</h4>
<h4 id="2反爬虫机制访问频率限制">2.反爬虫机制:访问频率限制</h4>
<h4 id="应对机制">应对机制:</h4>
<h4 id="修改访问频率限制通过-post-方式修改-read_time正常访问的话这个值一般会大于10如果我们修改成-60">* 	修改访问频率限制,通过 POST 方式，修改 read_time，正常访问的话，这个值一般会大于10如果我们修改成 60.</h4>
<h4 id="代理pi访问通过多个代理ip访问降低单个ip访问频率突破该机制">* 	代理PI访问,通过多个代理IP访问降低单个IP访问频率突破该机制</h4>
<h4 id="分布式爬虫通过部署在多个服务器上的爬虫程序统一从一个地方拿网址平均下来每个服务器访问频率降低-从而突破限制同时实现的爬虫会更加的稳定和高效">* 	分布式爬虫,通过部署在多个服务器上的爬虫程序统一从一个地方拿网址,,平均下来每个服务器访问频率降低 ,从而突破限制,同时实现的爬虫会更加的稳定和高效</h4>
<h4 id="3-反爬虫机制蜜罐技术">3. 反爬虫机制:蜜罐技术</h4>
<h5 id="在反爬虫的机制中有一种蜜罐技术-网页上会故意留下一些人类看不到或者绝对不会点击的链接-由于爬虫会从源代码中获取内容所以爬虫可能会访问这样的链接-这个时候只要网站发现了有ip访问这个链接立刻永久封禁该ip-user-agent-mac地址等等可以用于识别访问者身份的所有信息"><code>在反爬虫的机制中，有一种蜜罐技术。网页上会故意留下一些人类看不到或者绝对不会点击的链接。由于爬虫会从源代码中获取内容，所以爬虫可能会访问这样的链接。这个时候，只要网站发现了有IP访问这个链接，立刻永久封禁该IP + User-Agent + Mac地址等等可以用于识别访问者身份的所有信息。</code></h5>
<h4 id="应对机制定向爬虫技术">应对机制:定向爬虫技术</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leaning Summary 7-05]]></title>
        <id>https://Superbishop.github.io/post/3vAt6NvMi</id>
        <link href="https://Superbishop.github.io/post/3vAt6NvMi">
        </link>
        <updated>2019-07-05T02:48:34.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>argv 和input()的不同点:<br>
用户输入时机的不同.如果参数是在用户执行命令时就要输入,使用argv;若是在脚本运行过程中需要用户输入,则使用input().<br>
2.与文件相关的命令(方法/函数):</li>
</ol>
<ul>
<li>close:关闭文件</li>
<li>read:读取文件的内容.你可以把结果赋给一个变量.</li>
<li>readline:只读取文本文件中的一行</li>
<li>truncate:清空文件,慎用</li>
<li>write('stuff'):将struff写入文件</li>
<li>seek(0):将读写位置移到文件开头</li>
</ul>
<p>Q:如何在文件用一次write命令写入多个字符串且用转义字符进行排版?</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Summary-6-14-2019]]></title>
        <id>https://Superbishop.github.io/post/learning-summary-6-14-2019</id>
        <link href="https://Superbishop.github.io/post/learning-summary-6-14-2019">
        </link>
        <updated>2019-06-15T22:31:38.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>use &quot;\n&quot; to let code to print in next line.</li>
</ul>
<hr>
<ul>
<li>when using three double-quotes, we can edite codes as much as we can and print out to show as what we edit in the quotes.</li>
</ul>
<hr>
<ul>
<li>there are two ways to  format string variable:</li>
</ul>
<ol>
<li>f&quot;some stuff {somevar}&quot;,but we need to define somevar=xxx before.</li>
<li>&quot;some stuff {}&quot;.format(text what you like)</li>
</ol>
]]></content>
    </entry>
</feed>
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Superbishop.github.io</id>
    <title>Bishop&apos;s Learning Space</title>
    <updated>2019-09-23T03:52:20.792Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Superbishop.github.io"/>
    <link rel="self" href="https://Superbishop.github.io/atom.xml"/>
    <subtitle>Live and learn. </subtitle>
    <logo>https://Superbishop.github.io/images/avatar.png</logo>
    <icon>https://Superbishop.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Bishop&apos;s Learning Space</rights>
    <entry>
        <title type="html"><![CDATA[正则表达式]]></title>
        <id>https://Superbishop.github.io/post/qlZcHAhor</id>
        <link href="https://Superbishop.github.io/post/qlZcHAhor">
        </link>
        <updated>2019-09-10T03:51:52.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p><strong>概念:针对字符串进行数据筛选的表达式(匹配), eg:  import re</strong></p>
</li>
<li>
<p><strong>原子:正则表达式中实现匹配的基本单位</strong></p>
</li>
<li>
<p>以普通字符作为原子</p>
</li>
<li>
<p>匹配通用字符<br>
\w 任意字母/数字/下划线<br>
\W 和小写w相反<br>
\d 十进制数字<br>
\D 除了十进制数以外的值<br>
\s 空白字符<br>
\S 非空白字符</p>
</li>
<li>
<p>匹配数字/英文/中文<br>
数字 [0,9]<br>
英文 [a,z][A,Z]<br>
中文[\u4e00-\u9fa5]</p>
</li>
<li>
<p>原子表:定义一组平等的原子, eg:  pat=&quot;1[3578]\d\d\d\d\d\d\d\d\d&quot;</p>
</li>
<li>
<p><strong>元字符:正则表达式中具有特殊意义的字符</strong><br>
.     匹配任意字符(\n 除外)<br>
^   匹配字符串开始位置 eg: ^136<br>
$    匹配字符串中结束的位置 eg:666$<br>
&quot;*&quot;    重复0/1/多次前面原子   eg: \d<br>
?      重复0/1次前面的原子   eg:\d?<br>
&quot;+&quot;  重复1/多次前面的原子 eg:\d+</p>
</li>
</ul>
<p>匹配固定次数<br>
{n} 前面的原子出现n次<br>
{n,} 前面的原子出现至少出现n次<br>
{n,m} 出现次数介于n-m之间</p>
<ul>
<li><strong>多个正则表达式可用或&quot;|&quot;符号连接,从而实现多种数据匹配</strong></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[处理get请求]]></title>
        <id>https://Superbishop.github.io/post/l99V4EeeY</id>
        <link href="https://Superbishop.github.io/post/l99V4EeeY">
        </link>
        <updated>2019-07-28T03:58:42.000Z</updated>
        <content type="html"><![CDATA[<pre><code>import urllib
from urllib import request
# https://www.baidu.com/s?wd=%E5%85%8D%E8%B4%B9%E4%BB%A3%E7%90%86IP # url 编码
url = &quot;http://www.baidu.com/s?&quot;
wd = {&quot;wd&quot;:&quot;免费代理IP&quot;}

# 构造url编码
wdd = urllib.parse.urlencode(wd)

url = url + wdd
req = request.Request(url)
response = request.urlopen(req)
print(response.read().decode())
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[反爬虫机制2:代理IP爬去网站]]></title>
        <id>https://Superbishop.github.io/post/o3jSS0M9C</id>
        <link href="https://Superbishop.github.io/post/o3jSS0M9C">
        </link>
        <updated>2019-07-28T02:55:46.000Z</updated>
        <content type="html"><![CDATA[<pre><code>proxylist = [
    {&quot;http&quot;:&quot;47.107.186.18:8118&quot;},
    {&quot;http&quot;:&quot;101.132.164.113:8118&quot;},
    {&quot;http&quot;:&quot;121.232.194.196:9000&quot;},
    {&quot;http&quot;:&quot;112.111.97.101:9000&quot;},
    {&quot;http&quot;:&quot;175.44.151.198:9000&quot;}
]

# 随机选取代理IP
proxy = random.choice(proxylist)
print(proxy)

# 构建代理处理器对象
proxyHandler = request.ProxyHandler(proxy)

# 创建自定义opener
opener = request.build_opener(proxyHandler)

# 创建自定义请求对象
request = request.Request(url)

response = opener.open(request)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[自定义opener 以及全局opener的创建方法]]></title>
        <id>https://Superbishop.github.io/post/TbXZS3u2p</id>
        <link href="https://Superbishop.github.io/post/TbXZS3u2p">
        </link>
        <updated>2019-07-17T06:07:36.000Z</updated>
        <content type="html"><![CDATA[<h4 id="通常我们默认使用的urlopen它是一个特殊的opener也就是模块自动构建好的但基本的urlopen不支持代理ipcookie等其他httphttps高级功能因此需要自动以opener">通常我们默认使用的urlopen,它是一个特殊的opener,也就是模块自动构建好的,但基本的urlopen()不支持代理IP/cookie等其他HTTP/HTTPS高级功能,因此需要自动以opener.</h4>
<h5 id="通过-reqeustbuildopener创建自定义opener对象使用自定义的opener对象调用open方法发送请求">* 通过 reqeust.build.opener()创建自定义opener对象,使用自定义的opener对象,调用open()方法发送请求</h5>
<h5 id="若程序全局都使用自定义opener通过requestinstallopener将自定义的opener对象定义为全局opener即若之后凡是调用urlopen都将使用该opener">* 若程序全局都使用自定义opener,通过request.install.opener()将自定义的opener对象定义为全局opener,即若之后凡是调用urlopen,都将使用该opener</h5>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[反爬虫机制一]]></title>
        <id>https://Superbishop.github.io/post/yzZXoI4C0</id>
        <link href="https://Superbishop.github.io/post/yzZXoI4C0">
        </link>
        <updated>2019-07-17T05:14:28.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<h4 id="反爬虫机制一判断用户是否是浏览器访问而非通过爬虫程序的urllib进行访问">反爬虫机制一:判断用户是否是浏览器访问,而非通过爬虫程序的urllib进行访问</h4>
</li>
<li>
<h4 id="应对方法伪装浏览器进行访问">应对方法:伪装浏览器进行访问</h4>
</li>
</ul>
<pre><code>header={
&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot;
} #构造请求头信息,包含进user-agent信息

req=request.Request(url,headers=header)#自定义请求对象将构造的请求头封装进去


</code></pre>
<h4 id="同时很多时候会添加多个user-agent进行随机爬虫防止被网页识别并拦截"><strong>同时,很多时候会添加多个user-agent进行随机爬虫,防止被网页识别并拦截</strong></h4>
]]></content>
    </entry>
</feed>